# awesome-multimodal-representation-learning

Buildling multimodal representations "AI systems that learn about concepts in several modalities, primarily the textual and visual domains, in order to better understand the world. In our latest research announcements, we present two neural networks that bring us closer to this goal."

## Outline 
- [TEMP PLACEHOLDER]
- 
## Transformer-based
- **Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks**, (2020) [[paper]](https://arxiv.org/pdf/2004.06165.pdf), by *Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, Yejin Choi, and Jianfeng Gao*
- Transformer is all you need: Multimodal multitask learning with a unified transformer
- **ROSITA: Enhancing Vision-and-Language Semantic Alignments via Cross-and Intra-modal Knowledge Integration**, (2021) [[paper]](https://dl.acm.org/doi/pdf/10.1145/3474085.3475251), by *Yuhao Cui, Zhou Yu, Chunqi Wang, Zhongzhou Zhao, Ji Zhang, Meng Wang, and Jun Yu*


## Contrastive Learning
- **Learning Transferable Visual Models From Natural Language Supervision**, (2020) [[paper]](https://arxiv.org/pdf/2103.00020.pdf), by *Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever* 

## Useful Blogs and Videos
- **OpenAI Multimodal Research** [[website]](https://openai.com/blog/tags/multimodal/)
  - [[Blog--DALLÂ·E: Creating Images from Text]](https://openai.com/blog/dall-e/), by *(primary authors) Aditya RameshMikhail PavlovGabriel GohScott Gray, (supporting authors) Mark Chen, Rewon Child, Vedant Misra, Pamela Mishkin, Gretchen Krueger, Sandhini Agarwal, and Ilya Sutskever*, Jan 2021
  - [[Blog--CLIP: Connecting Text and Images]](https://openai.com/blog/clip/), by *Alec Radford, Ilya Sutskever, Jong Wook Kim, Gretchen Krueger, and Sandhini Agarwal*, Jan 2021
  - [[Blog--Simple Implementation of OpenAI CLIP model: A Tutorial]](https://towardsdatascience.com/simple-implementation-of-openai-clip-model-a-tutorial-ace6ff01d9f2), by *Moein Shariatnia*, April 2021
  - [[Blog--Multimodal Neurons in Artificial Neural Networks]](https://openai.com/blog/multimodal-neurons/), by *Gabriel Goh, Chelsea Voss, Daniela Amodei, Shan Carter, Michael Petrov, Justin Jay Wang, Nick Cammarata, and Chris Olah*, March 2021

- **Microsoft Multimodal AI** [[website]](https://multimodalai.azurewebsites.net/)
  - [[CVPR 2020 Tutorial--Recent Advances in Vision-and-Language Research]](https://rohit497.github.io/Recent-Advances-in-Vision-and-Language-Research/), June 2020
    - [[Youtube--CVPR 2020 Tutorial: Talk #1]](https://www.youtube.com/watch?v=BJgzjNN3h1U) Opening Remarks by JJ Liu
    - [[Youtube--CVPR 2020 Tutorial: Talk #2]](https://www.youtube.com/watch?v=n4mUriUrYR0) Visual QA and Reasoning by Zhe Gan
    - [[Youtube--CVPR 2020 Tutorial: Talk #3]](https://www.youtube.com/watch?v=Zn5uFGsq4j4) Visual Captioning by Luowei Zhou
    - [[Youtube--CVPR 2020 Tutorial: Talk #4]](https://www.youtube.com/watch?v=8pNtrsFe4tk) Text-to-Image Generation by Yu Cheng
    - [[Youtube--CVPR 2020 Tutorial: Talk #5]](https://www.youtube.com/watch?v=C4UQWJcp7w4) Self-supervised Learning by Licheng Yu, Yen-Chun Chen and Linjie Li
  - [[Blog--UNITER: Combining Image and Text]](https://towardsdatascience.com/uniter-d979e2d838f0), by "Rohit Pillai*, May 2020
  - [[Blog--VIOLIN: Do you really understand videos?]](https://medium.com/swlh/violin-do-you-really-understand-videos-fe07f7affd9e), by "Rohit Pillai*, May 2020
  - [[Youtube--AI Advances in Image Captioning: Describing Images as Well as People Do]](https://www.youtube.com/watch?v=QNesnXfyYq8), by *Lijuan Wang and Xiaowei Hu*, Mar 2021
